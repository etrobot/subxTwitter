<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/html">

<head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>GPT Subscripton to Twitter List</title>
    <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
    <link rel="stylesheet" href="/static/style.css">
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7398757278741889"
         crossorigin="anonymous"></script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-XV4CMHELK9"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('config', 'G-XV4CMHELK9');
    </script>
</head>

<body class="bg-gray-50 dark">

<div class="sidebar w-full max-w-sm items-center">
    <div>
        <button id="theme-toggle" class="px-2 rounded">🌒</button>
    </div>
    <div class="w-full text-center font-bold">
        <div class="title">GPT Subscripton to Twitter List</div>
    </div>
    <div class="text-xs my-4 w-80 m-auto leading-loose">
        <a href="/lang/zh-CN" class="border-b-2 mr-2">简体中文</a>
        <a href="/lang/zh-TW" class="border-b-2 mr-2">繁體中文</a>
        <a href="/lang/en" class="border-b-2 mr-2">English</a>
        <a href="/lang/ja" class="border-b-2 mr-2">日本語</a>
        <a href="/lang/ko" class="border-b-2 mr-2">한국어</a>
        <a href="/lang/es" class="border-b-2 mr-2">Español</a>
        <a href="/lang/pt" class="border-b-2 mr-2">Português</a>
        <a href="/lang/de" class="border-b-2 mr-2">Deutsch</a>
        <a href="/lang/fr" class="border-b-2 mr-2">Français</a>
        <a href="/lang/ar" class="border-b-2 mr-2">العربية</a>
        <a href="/lang/id" class="border-b-2 mr-2">Bahasa Indonesia</a>
        <a href="/lang/ms" class="border-b-2 mr-2">Bahasa Melayu</a>
        <a href="/lang/tl" class="border-b-2 mr-2">Filipino</a>
        <a href="/lang/vi" class="border-b-2 mr-2">Tiếng Việt</a>
        <a href="/lang/pl" class="border-b-2 mr-2">Polski</a>
        <a href="/lang/nl" class="border-b-2 mr-2">Nederlands</a>
        <a href="/lang/th" class="border-b-2 mr-2">ไทย</a>
        <a href="/static/privacy.html" class="text-blue-500 border-b-2 mr-2">Privacy</a>
    </div>
<div class="w-full text-center">
    <a target=_blank href="https://discord.com/api/oauth2/authorize?client_id=1185508364701151284&permissions=8797166831616&scope=bot" class="mt-4 text-white bg-blue-700 hover:bg-blue-800 focus:ring-4 focus:ring-blue-300 font-medium rounded-full text-sm px-5 py-1 dark:bg-blue-600 dark:hover:bg-blue-700 focus:outline-none dark:focus:ring-blue-800">Chat GPT-4 Free</a>
</div>
</div>
<div id="parentContainer" class="flex flex-wrap m-2">
    
    <div class="flex flex-col rounded-xl my-1 p-4 bg-gray-500 bg-opacity-5 max-w-screen-md mx-auto">
        <div class="flex w-full items-center space-x-2 max-w-screen-lg">
            <div class="w-16 h-10 rounded overflow-hidden">
                <img src="https://pbs.twimg.com/list_banner_img/1733654690490200064/ig-cUZfi?format=jpg&name=360x360" class="object-none w-full h-full"/>
            </div>

            <a class="text-sm w-full" href="https://twitter.com/i/lists/1733652180576686386">
                <div class="font-bold">AGI Thoughts</div>
                <div class="text-gray-500">1733652180576686386</div>
            </a>
            <button class="subx bg-blue-400 text-white px-3 py-1  rounded-full" value="1733652180576686386">🔔</button>
        </div>
        <div class="mt-2 text-sm">
            <h1>Berita Terbaru</h1>
<p><a style="color:#5da2ff;" href="https://x.com/ylecun/status/1748557610855399710#m">20 Jan 2024 04:06:35 @ylecun</a>: AI bisa membantu dalam menangkap karbon.</p>
<p>Quoting:</p>
<blockquote>
<p>Peneliti Meta dan <a href="https://x.com/GeorgiaTech" title="Georgia Tech">@GeorgiaTech</a> merilis dataset + model AI untuk mempercepat penelitian tentang Direct Air Capture — teknologi kunci yang diperlukan untuk melawan perubahan iklim.  </p>
<p>Dapatkan model &amp; dataset ➡️ <a href="https://bit.ly/47gEKfy">bit.ly/47gEKfy</a>  </p>
<p>OpenDAC23 adalah dataset terbesar dari jenisnya pada tingkat akurasi DFT, dan kami berharap pekerjaan ini akan mempercepat penelitian di bidang studi penting ini.  </p>
</blockquote>
<p><img src="https://nitter.catsarch.com/pic/media%2FGEJk_cpbkAAksjn.jpg" />
<a href="https://x.com/AIatMeta/status/1748070705676386347#m">x.com/AIatMeta/status/1748070705676386347#m</a></p>
<p>Meta dan peneliti dari <a href="https://x.com/GeorgiaTech" title="Georgia Tech">@GeorgiaTech</a> telah merilis dataset + model AI untuk membantu mempercepat penelitian tentang Direct Air Capture — teknologi kunci yang diperlukan untuk melawan perubahan iklim.</p>
<p>Dapatkan model &amp; dataset ➡️ <a href="https://bit.ly/47gEKfy">bit.ly/47gEKfy</a></p>
<p>OpenDAC23 adalah dataset terbesar dari jenisnya pada tingkat akurasi DFT, dan kami berharap pekerjaan ini akan mempercepat penelitian di bidang studi penting ini.</p>
<p><img style="max-height: 16rem;margin:1rem;" alt="" src="https://nitter.catsarch.com/pic/media%2FGEJk_cpbkAAksjn.jpg" /></p>
<p><a style="color:#5da2ff;" href="https://x.com/IlyesBatatia/status/1742238047725326431#m">02 Jan 2024 17:34:54 @IlyesBatatia</a>: Upaya kolaboratif besar kami menunjukkan jangkauan aplikasi yang mengesankan dari potensi ML foundational, dikembangkan menggunakan hanya data dan perangkat lunak open-source. Lebih dari 30 aplikasi, termasuk MOF, katalisis, air, dan lainnya disimulasikan dengan satu model.<br />
<a href="https://arxiv.org/abs/2401.00096">arxiv.org/abs/2401.00096</a></p>
<p><img style="max-height: 16rem;margin:1rem;" alt="" src="https://nitter.catsarch.com/pic/media%2FGC2nHHRW0AAKijC.png" /></p>
<p>Upaya kolaboratif besar kami menunjukkan jangkauan aplikasi yang mengesankan dari potensi ML foundational, dikembangkan menggunakan hanya data dan perangkat lunak open-source. Lebih dari 30 aplikasi, termasuk MOF, katalisis, air, dan lainnya disimulasikan dengan satu model.</p>
<p><a style="color:#5da2ff;" href="https://x.com/AravSrinivas/status/1748533903038521731#m">20 Jan 2024 02:32:23 @AravSrinivas</a>: Paris sedang mempercepat</p>
<p><img style="max-height: 16rem;margin:1rem;" alt="" src="https://nitter.catsarch.com/pic/media%2FGEQKUNebgAAPCOJ.jpg" /></p>
<p>Paris sedang mempercepat</p>
<p><a style="color:#5da2ff;" href="https://x.com/NYUDataScience/status/1748391439187472563#m">19 Jan 2024 17:06:17 @NYUDataScience</a>: Data science memang untuk semua orang! Kami sangat senang untuk mengumumkan rilis buku kursus baru dan seri video yang terinspirasi oleh "Data Science for Everyone", kursus sarjana populer kami.</p>
<p><a style="color:#5da2ff;" href="https://x.com/ylecun/status/1748531221989142822#m">20 Jan 2024 02:21:44 @ylecun</a>: Menghapus satu spasi bisa membuat frase kehilangan seluruh maknanya, seperti "Open AI" -&gt; "OpenAI" dan juga seperti "Le Cun" -&gt; "LeCun" 😱</p>
<p>Quoting: </p>
<blockquote>
<p>Bindu Reddy (@bindureddy): "Zuck dan Yann LeCunn akan diabadikan sebagai pahlawan dalam sejarah manusia!  </p>
<p>Berjuang untuk Open AI ketika incumbents berusaha untuk menutupnya!  </p>
<p>Sungguh luar biasa bagaimana energi dari Meta telah berubah selama setahun terakhir. 🤯🤯  </p>
<p>Selain itu, mungkin saatnya untuk mengubah nama - Meta menjadi OpenAI 😉" | Nitter<br />
<a href="https://x.com/bindureddy/status/1748458990974247401#m">x.com/bindureddy/status/1748458990974247401#m</a></p>
</blockquote>
<p>Zuck dan Yann LeCunn akan diabadikan sebagai pahlawan dalam sejarah manusia!  </p>
<p>Berjuang untuk Open AI ketika incumbents berusaha untuk menutupnya!  </p>
<p>Sungguh luar biasa bagaimana energi dari Meta telah berubah selama setahun terakhir. 🤯🤯  </p>
<p>Selain itu, mungkin saatnya untuk mengubah nama - Meta menjadi OpenAI 😉</p>
<p><a style="color:#5da2ff;" href="https://x.com/ylecun/status/1748526916104020125#m">20 Jan 2024 02:04:37 @ylecun</a>: Saya memiliki nama yang lebih sederhana untuk "group attention": pooling.</p>
<p>Quoting: </p>
<blockquote>
<p>Cameron R. Wolfe, Ph.D. (@cwolferesearch): "Kemampuan belajar konteks yang mengesankan dari LLM telah menciptakan kebutuhan akan jendela konteks yang lebih besar. Baru-baru ini, peneliti menemukan bahwa kita dapat dengan mudah memperluas jendela konteks dari LLM yang sudah terlatih dengan satu trik sederhana (dan tanpa pelatihan tambahan)...  </p>
<p>Apa itu jendela konteks? Selama pra-pelatihan, sebuah LLM melihat urutan input dari panjang tertentu. Pilihan panjang urutan ini selama pra-pelatihan menjadi panjang konteks model, atau urutan teks maksimum yang dapat diproses model. Di luar panjang konteks ini, model mungkin bertindak secara tidak terduga dan menghasilkan output yang salah.  </p>
<p>Mengapa kita membutuhkan jendela konteks yang besar? Praktisi ingin kemampuan untuk melewati lebih banyak data ke dalam jendela konteks LLM untuk memungkinkan aplikasi yang lebih kompleks melalui pendekatan seperti pembelajaran sedikit (atau bahkan pendekatan pendorong yang lebih kompleks seperti pendorong berantai pikiran) dan generasi pemerolehan dijinakkan (RAG). Meskipun beberapa LLM konteks panjang telah dirilis (misalnya, Claude 2.1 dan GPT-4-Turbo), tidak semua LLM telah dilatih untuk mendukung konteks panjang, dan LLM open-source cenderung hanya mendukung konteks lebih pendek dibandingkan dengan alternatif-properti mereka.  </p>
<p>Memperluas jendela konteks. Untuk memperluas jendela konteks LLM yang sudah terlatih, kita dapat mengatur ulang model melalui contoh urutan yang lebih panjang, tetapi pendekatan seperti itu mungkin menyebabkan model terlalu disesuaikan dengan contoh spesifik urutan panjang. Beberapa pendekatan telah diusulkan untuk memperluas jendela konteks LLM tanpa (atau minimal) penyesuaian seperti PI, CLEX, dan YARN. Selain itu, pendekatan-pendekatan yang umum seperti ALiBi dan RoPE mengaktifkan LLM untuk menangani masukan lebih panjang selama inferensi dibandingkan dengan yang dilihat selama pelatihan.</p>
<p>Mengapa LLM tidak bisa menggeneralisasi ke urutan yang lebih panjang? Masalah kunci yang dihadapi oleh LLM dalam mengeneralisasi ke jendela konteks yang lebih panjang terkait dengan enkoding posisional out-of-distribution, di mana LLM terpapar pada jarak relatif dan posisi token yang melebihi apa yang terlihat selama pelatihan. Kita dapat dengan mudah mengatasi masalah ini dengan mengatur ulang posisi yang tidak terlihat ke posisi yang ditemui selama pelatihan.  </p>
<p>"Untuk mengatasi ini, solusi yang intuitif dan praktis akan mengatur ulang posisi relatif yang tidak terlihat ke posisi yang ditemui selama pra-pelatihan, sehingga memperpanjang kemampuan LLM untuk menangani konteks yang lebih panjang secara alami." - dari paper Self Extend</p>
<p>Grouped Attention. Dalam "LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning", penulis berpendapat bahwa LLM memiliki kemampuan bawaan untuk menangani urutan panjang yang dapat dimanfaatkan tanpa pelatihan tambahan. Kita dapat menggunakan operasi FLOOR yang melakukan pembagian bilangan bulat pada indeks posisi sehingga indeks posisi maksimum yang dilihat selama inferensi tidak melebihi panjang konteks model yang telah ditentukan. Meskipun hal ini bisa menyebabkan token-tokem yang berdekatan diberikan ke indeks posisi yang sama, hal ini masih berfungsi dengan baik dalam praktik karena:  </p>
<ol>
<li>Posisi yang tepat dari token kurang penting dibandingkan dengan urutan relatif saat mencoba memahami urutan teks.</li>
<li>Urutan token pendek cenderung hanya memiliki satu urutan yang valid, sehingga memberikan mereka ke indeks posisi yang sama memiliki sedikit dampak praktis.  </li>
</ol>
<p>Pendekatan semacam ini, disebut "grouped attention" karena kami mengelompokkan beberapa token ke dalam embedding posisi yang sama, berkinerja sebanding dengan teknik penyesuaian untuk memperluas jendela konteks dan hanya memerlukan beberapa modifikasi kode minimal (yaitu, hanya empat baris ekstra di PyTorch).</p>
<p>Self Extend. Jika kita dengan naif menerapkan grouped attention, kinerja pemodelan bahasa sedikit menurun, karena token sepanjang urutan dipetakan ke dalam grup yang berbagi indeks posisi yang sama. Untuk mengatasi masalah ini, kita perlu memahami bahwa token tetangga paling penting saat menghasilkan token dengan LLM. Jadi, kita dapat menghilangkan degradasi kinerja ini dengan:</p>
<ol>
<li>Mendefinisikan ukuran tetangga dari token paling baru-baru ini di atas mana perhatian normal diterapkan.  </li>
<li>Menggunakan grouped attention untuk token-tokem yang jauh di dalam urutan.  </li>
</ol>
<p>Trik terakhir ini membentuk teknik Self Extend, yang dapat digunakan untuk meningkatkan panjang konteks dari setiap LLM pada saat inferensi tanpa perlu penyetelan ulang. | Nitter<br />
<a href="https://x.com/cwolferesearch/status/1748393116338409890#m">x.com/cwolferesearch/status/1748393116338409890#m</a></p>
</blockquote>
<p>Kemampuan belajar konteks yang mengesankan dari LLM telah menciptakan kebutuhan akan jendela konteks yang lebih besar. Baru-baru ini, peneliti menemukan bahwa kita dapat dengan mudah memperluas jendela konteks dari LLM yang sudah terlatih dengan satu trik sederhana (dan tanpa pelatihan tambahan)...</p>
<p><img src="https://nitter.catsarch.com/pic/media%2FGEOJzhKXMAA5_hB.jpg" /></p>
<p>Menarik, bukan? Terima kasih telah membaca artikel terbaru kami! Segera kunjungi situs web kami untuk informasi lebih lanjut.</p>
        </div><br><br><br><br><br><br>
    </div>

</div>
<div class="flex flex-col fixed bottom-0 w-full subcard backdrop-filter backdrop-blur-lg">
    <div class="text-sm px-2 pb-2 pt-2">
        <form id="subscribe-form" action="/subscribe" method="post" class="flex flex-col mb-2">
            <div class="flex items-center  w-full">
                <input type="number" name="target_id" placeholder="Enter target ID" required
                       class="m-1 border border-gray-300 rounded px-4 py-1 focus:outline-none focus:ring focus:border-blue-300  w-full">
                <a href="https://business.twitter.com/en/blog/twitter-101-lists.html" target="_blank"
                   rel="noopener noreferrer"
                   class="border border-white rounded px-3 py-1  mr-2">
                    ?
                </a>
            </div>
            <div class="flex items-center mt-1 w-full">
                <input type="email" name="email" placeholder="Enter your email address" required
                       class="m-1 border border-gray-300 rounded px-4 py-1 focus:outline-none focus:ring focus:border-blue-300 w-full max-w-xs">
                <select id="language-select"
                        class="w-1/2 border border-white mr-1 ml-auto bg-transparent py-1 rounded">
                    <option value="zh-CN">简体中文</option>
                    <option value="zh-TW">繁體中文</option>
                    <option value="en">English</option>
                    <option value="ja">日本語</option>
                    <option value="ko">한국어</option>
                    <option value="es">Español</option>
                    <option value="pt">Português</option>
                    <option value="de">Deutsch</option>
                    <option value="fr">Français</option>
                    <option value="ar">العربية</option>
                    <option value="id">Bahasa Indonesia</option>
                    <option value="ms">Bahasa Melayu</option>
                    <option value="tl">Filipino</option>
                    <option value="vi">Tiếng Việt</option>
                    <option value="pl">Polski</option>
                    <option value="nl">Nederlands</option>
                    <option value="th">ไทย</option>
                </select>
            </div>
            <div class="flex mt-1 w-full">
                <input type="time" id="mail-time" required
                       class="w-20 m-1 border border-gray-300 rounded-full py-1 focus:ring focus:border-blue-300">
                <button type="submit" class="bg-blue-500 text-white py-1 rounded-full m-1 w-full"
                        id="subscribe-btn">Subscribe
                </button>
                <input type="hidden" name="mail_time" id="mail-time-timestamp" value="">
            </div>
            <input type="hidden" name="current_language" id="current-language" value="">

        </form>
        <span class="text-xs" id="time-label">Daily Push Time</span><span class="fixed bottom-2 right-2">© subxTwitter 2024</span>
    </div>
</div>
</body>
<script src="/static/index.js"></script>
</html>