<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/html">

<head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>GPT Subscripton to Twitter List</title>
    <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
    <link rel="stylesheet" href="/static/style.css">
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7398757278741889"
         crossorigin="anonymous"></script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-XV4CMHELK9"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('config', 'G-XV4CMHELK9');
    </script>
</head>

<body class="bg-gray-50 dark">

<div class="sidebar w-full max-w-sm items-center">
    <div>
        <button id="theme-toggle" class="px-2 rounded">🌒</button>
    </div>
    <div class="w-full text-center font-bold">
        <div class="title">GPT Subscripton to Twitter List</div>
    </div>
    <div class="text-xs my-4 w-80 m-auto leading-loose">
        <a href="/lang/zh-CN" class="border-b-2 mr-2">简体中文</a>
        <a href="/lang/zh-TW" class="border-b-2 mr-2">繁體中文</a>
        <a href="/lang/en" class="border-b-2 mr-2">English</a>
        <a href="/lang/ja" class="border-b-2 mr-2">日本語</a>
        <a href="/lang/ko" class="border-b-2 mr-2">한국어</a>
        <a href="/lang/es" class="border-b-2 mr-2">Español</a>
        <a href="/lang/pt" class="border-b-2 mr-2">Português</a>
        <a href="/lang/de" class="border-b-2 mr-2">Deutsch</a>
        <a href="/lang/fr" class="border-b-2 mr-2">Français</a>
        <a href="/lang/ar" class="border-b-2 mr-2">العربية</a>
        <a href="/lang/id" class="border-b-2 mr-2">Bahasa Indonesia</a>
        <a href="/lang/ms" class="border-b-2 mr-2">Bahasa Melayu</a>
        <a href="/lang/tl" class="border-b-2 mr-2">Filipino</a>
        <a href="/lang/vi" class="border-b-2 mr-2">Tiếng Việt</a>
        <a href="/lang/pl" class="border-b-2 mr-2">Polski</a>
        <a href="/lang/nl" class="border-b-2 mr-2">Nederlands</a>
        <a href="/lang/th" class="border-b-2 mr-2">ไทย</a>
        <a href="/static/privacy.html" class="text-blue-500 border-b-2 mr-2">Privacy</a>
    </div>
<div class="w-full text-center">
    <a target=_blank href="https://discord.com/api/oauth2/authorize?client_id=1185508364701151284&permissions=8797166831616&scope=bot" class="mt-4 text-white bg-blue-700 hover:bg-blue-800 focus:ring-4 focus:ring-blue-300 font-medium rounded-full text-sm px-5 py-1 dark:bg-blue-600 dark:hover:bg-blue-700 focus:outline-none dark:focus:ring-blue-800">Chat GPT-4 Free</a>
</div>
</div>
<div id="parentContainer" class="flex flex-wrap m-2">
    
    <div class="flex flex-col rounded-xl my-1 p-4 bg-gray-500 bg-opacity-5 max-w-screen-md mx-auto">
        <div class="flex w-full items-center space-x-2 max-w-screen-lg">
            <div class="w-16 h-10 rounded overflow-hidden">
                <img src="https://pbs.twimg.com/list_banner_img/1733654690490200064/ig-cUZfi?format=jpg&name=360x360" class="object-none w-full h-full"/>
            </div>

            <a class="text-sm w-full" href="https://twitter.com/i/lists/1733652180576686386">
                <div class="font-bold">AGI Thoughts</div>
                <div class="text-gray-500">1733652180576686386</div>
            </a>
            <button class="subx bg-blue-400 text-white px-3 py-1  rounded-full" value="1733652180576686386">🔔</button>
        </div>
        <div class="mt-2 text-sm">
            <h1>Tống hợp tweets mới nhất về các phát hiện và công bố mới trong lĩnh vực Trí tuệ nhân tạo và khoa học dữ liệu.</h1>
<p><a style="color:#5da2ff;" href="https://x.com/ylecun/status/1748559301923274970#m">20 Tháng 1 năm 2024 04:13:18 @ylecun</a>: LLM tự thưởng. Từ FAIR+NYU.</p>
<p>Quoting: </p>
<blockquote>
<p>Jason Weston (@jaseweston): "Bài báo mới! 
LLM tự thưởng 
- LLM tự cung cấp phần thưởng của riêng mình trong quá trình tạo ra dữ liệu thông qua LLM-như-một-Trọng tài trong quá trình huấn luyện DPO lặp đi lặp lại 
- Khả năng tạo mô hình thưởng tăng lên trong quá trình huấn luyện thay vì cố định
...mở ra cánh cửa cho phản hồi siêu người? 
<a href="https://arxiv.org/abs/2401.10020">arxiv.org/abs/2401.10020</a> 
🧵(1/5)" | Nitter
x.com/jaseweston/status/1748158323369611577#m</p>
</blockquote>
<p>Bài báo mới!<br />
LLM tự thưởng<br />
- LLM tự cung cấp phần thưởng của riêng mình trong quá trình tạo ra dữ liệu thông qua LLM-như-một-Trọng tài trong quá trình huấn luyện DPO lặp đi lặp lại<br />
- Khả năng tạo mô hình thưởng tăng lên trong quá trình huấn luyện thay vì cố định<br />
...mở ra cánh cửa cho phản hồi siêu người?<br />
<a href="https://arxiv.org/abs/2401.10020">arxiv.org/abs/2401.10020</a><br />
🧵(1/5)</p>
<p><img style="max-height: 16rem;margin:1rem;" alt="" src="https://nitter.catsarch.com/pic/media%2FGEKUYslWcAEcmqy.png" /></p>
<h1>Trí tuệ nhân tạo có thể giúp đỡ trong việc hứng hợp cacbon.</h1>
<p>Quoting:</p>
<blockquote>
<p>Meta và <a href="https://x.com/GeorgiaTech" title="Georgia Tech">@GeorgiaTech</a> researchers released a dataset + AI models to help accelerate research on Direct Air Capture — a key technology needed to combat climate change.</p>
<p>Lấy các mô hình và dữ liệu ➡️ <a href="https://bit.ly/47gEKfy">bit.ly/47gEKfy</a>  </p>
<p>OpenDAC23 là tập dữ liệu lớn nhất từ trước đến nay ở mức độ chính xác DFT và chúng tôi hy vọng rằng công việc này sẽ giúp tăng tốc nghiên cứu trong lĩnh vực quan trọng này.</p>
<p><img style="max-height: 16rem;margin:1rem;" alt="" src="https://nitter.catsarch.com/pic/media%2FGEJk_cpbkAAksjn.jpg" />
x.com/AIatMeta/status/1748070705676386347#m</p>
</blockquote>
<p>Meta và <a href="https://x.com/GeorgiaTech" title="Georgia Tech">@GeorgiaTech</a> researchers ra mắt một bộ dữ liệu + các mô hình Trí tuệ nhân tạo để tăng tốc nghiên cứu về Tách khí trực tiếp - một công nghệ chính cần thiết để chống lại biến đổi khí hậu.</p>
<p>Lấy các mô hình và dữ liệu ➡️ <a href="https://bit.ly/47gEKfy">bit.ly/47gEKfy</a></p>
<p>OpenDAC23 là tập dữ liệu lớn nhất từ trước đến nay ở mức độ chính xác DFT và chúng tôi hy vọng rằng công việc này sẽ giúp tăng tốc nghiên cứu trong lĩnh vực quan trọng này.</p>
<p><img style="max-height: 16rem;margin:1rem;" alt="" src="https://nitter.catsarch.com/pic/media%2FGEJk_cpbkAAksjn.jpg" /></p>
<h1>Nỗ lực hợp tác lớn của chúng tôi cho thấy phạm vi ứng dụng ấn tượng của tiềm năng ML cơ bản, phát triển chỉ với dữ liệu và phần mềm mã nguồn mở. Hơn 30 ứng dụng, bao gồm MOFs, xúc tác, nước và nhiều hơn nữa được mô phỏng với một mô hình.</h1>
<p><a style="color:#5da2ff;" href="https://arxiv.org/abs/2401.00096">arxiv.org/abs/2401.00096</a></p>
<p><img style="max-height: 16rem;margin:1rem;" alt="" src="https://nitter.catsarch.com/pic/media%2FGC2nHHRW0AAKijC.png" /></p>
<h1>Paris đang tăng tốc</h1>
<p><img style="max-height: 16rem;margin:1rem;" alt="" src="https://nitter.catsarch.com/pic/media%2FGEQKUNebgAAPCOJ.jpg" /></p>
<h1>Khoa học dữ liệu đúng là dành cho mọi người! Chúng tôi rất vui mừng thông báo về việc phát hành cả cuốn sách khóa học mới và loạt video được tạo theo "Khoa học dữ liệu cho Mọi người", khóa học đại học phổ biến của chúng tôi.</h1>
<p><a style="color:#5da2ff;" href="https://x.com/ylecun/status/1748531221989142822#m">20 Tháng 1 năm 2024 02:21:44 @ylecun</a>: Loại bỏ một khoảng trống có thể làm mất đi ý nghĩa của một cụm từ, như trong
"AI mở" -&gt; "AI mở"
và cũng như trong
 "Le Cun" -&gt; "LeCun" 😱</p>
<p>Quoting: </p>
<blockquote>
<p>Bindu Reddy (@bindureddy): "Zuck và Yann LeCunn sẽ được đánh giá cao trong lịch sử nhân loại!</p>
<p>Chiến đấu cho Open AI khi những người đương nhiệm cố gắng đóng cửa nó!</p>
<p>Không thể tin được là tinh thần từ Meta đã thay đổi đến mức độ này chỉ trong một năm. 🤯🤯</p>
<p>Điều đó và có lẽ đã đến lúc thay đổi tên - Meta thành OpenAI 😉" | Nitter
x.com/bindureddy/status/1748458990974247401#m</p>
</blockquote>
<p>Zuck và Yann LeCunn sẽ được đánh giá cao trong lịch sử nhân loại!<br />
Chiến đấu cho Open AI khi những người đương nhiệm cố gắng đóng cửa nó!<br />
Không thể tin được là tinh thần từ Meta đã thay đổi đến mức độ này chỉ trong một năm. 🤯🤯<br />
Điều đó và có lẽ đã đến lúc thay đổi tên - Meta thành OpenAI 😉</p>
<p><a style="color:#5da2ff;" href="https://x.com/ylecun/status/1748526916104020125#m">20 Tháng 1 năm 2024 02:04:37 @ylecun</a>: Tôi có một tên đơn giản hơn cho "group attention": nhóm.</p>
<p>Quoting: </p>
<blockquote>
<p>Cameron R. Wolfe, Tiến sĩ (@cwolferesearch): "Các khả năng học thông tin trong bối cảnh ấn tượng của LLM đã tạo ra nhu cầu cho cửa sổ ngữ cảnh lớn hơn. Gần đây, các nhà nghiên cứu đã phát hiện rằng chúng ta có thể dễ dàng mở rộng cửa sổ ngữ cảnh của một LLM được huấn luyện trước bằng một mánh khóe đơn giản (và không cần huấn luyện thêm) …</p>
<p>Của sổ ngữ cảnh là gì? Trong quá trình huấn luyện trước, một LLM nhìn thấy chuỗi đầu vào với một độ dài cụ thể. Sự lựa chọn này về độ dài chuỗi trong quá trình huấn luyện trước trở thành độ dài ngữ cảnh của mô hình, hoặc chuỗi văn bản có độ dài tối đa mà mô hình có thể xử lý. Vượt qua độ dài ngữ cảnh này, mô hình có thể hoạt động một cách không lường trước và tạo ra đầu ra không chính xác.</p>
<p>Tại sao chúng ta cần một cửa sổ ngữ cảnh lớn? Người thực hành muốn khả năng đưa thêm dữ liệu vào cửa sổ ngữ cảnh của LLM để kích hoạt các ứng dụng phức tạp hơn thông qua các phương pháp như học ít điểm (hoặc thậm chí các phương pháp kích hoạt gợi ý phức tạp hơn như kích hoạt chuỗi suy nghĩ) và tạo ra kích hoạt tăng cường (RAG). Mặc dù đã có một số LLM ngữ cảnh dài (ví dụ, Claude 2.1 và GPT-4-Turbo), không phải LLM nào cũng được huấn luyện để hỗ trợ ngữ cảnh dài, và LLM mã nguồn mở có xu hướng chỉ hỗ trợ ngữ cảnh ngắn hơn so với những lựa chọn độc quyền của họ.</p>
<p>Mở rộng cửa sổ ngữ cảnh. Để mở rộng cửa sổ ngữ cảnh của một LLM được huấn luyện trước, chúng ta có thể tinh chỉnh mô hình qua các ví dụ của các chuỗi dài hơn, nhưng phương pháp như vậy có thể làm cho mô hình trở nên quá fitting vào các ví dụ cụ thể của các chuỗi dài. Nhiều phương pháp đã được đề xuất để mở rộng cửa sổ ngữ cảnh của một LLM mà không cần tinh chỉnh (hoặc tinh chỉnh tối thiểu) ngoại trừ PI, CLEX và YARN. Ngoài ra, các phương pháp thông dụng như ALiBi và RoPE cho phép LLM xử lý dữ liệu đầu vào dài hơn trong quá trình suy luận so với những gì nhìn thấy trong quá trình huấn luyện.</p>
<p>Tại sao các LLM không thể tổng quát cho các chuỗi dài hơn? Vấn đề chính mà LLM đối diện trong việc tổng quát hóa cho cửa sổ ngữ cảnh dài hơn liên quan đến các mã hóa vị trí nằm ngoài phạm vi phân phối, trong đó LLM được tiếp xúc với khoảng cách tương đối và vị trí token vượt quá những gì nhìn thấy trong quá trình huấn luyện. Chúng ta có thể dễ dàng giải quyết vấn đề này chỉ cần chuyển hóa lại những vị trí không nhìn thấy thành các vị trí đã gặp trong quá trình huấn luyện.</p>
<p>“Để giải quyết vấn đề này, một giải pháp hợp lý và thực tế sẽ là ánh xạ lại những vị trí tương đối không nhìn thấy thành những vị trí gặp trong quá trình huấn luyện trước đó, từ đó mở rộng khả năng xử lý ngữ cảnh dài của LLM một cách tự nhiên.” - từ bài báo Self Extend</p>
<p>Grouped Attention. Trong “LLM Có Thể Có Thể Dài hơn: Tự mở rộng Cửa sổ ngữ cảnh LLM Mà Không Cần Tinh Chỉnh”, các tác giả cho rằng LLM có khả năng bẩm sinh để xử lý các chuỗi dài có thể tận dụng mà không cần huấn luyện thêm. Chúng ta có thể sử dụng một hoạt động SÀN để thực hiện phép chia số nguyên trên các chỉ số vị trí sao cho chỉ số vị trí tối đa nhìn thấy trong quá trình suy luận không vượt quá độ dài ngữ cảnh đã xác định của mô hình. Mặc dù điều này có thể làm cho các token liền kề được gán cho cùng một chỉ số vị trí, nhưng nó vẫn hoạt động tốt trong thực tế bởi vì:</p>
<ol>
<li>Chính xác vị trí token ít quan trọng hơn so với thứ tự tương đối khi cố gắng hiểu một chuỗi văn bản.</li>
<li>Các chuỗi ngắn của token có xu hướng chỉ có một sắp xếp hợp lệ, vì vậy việc gán chúng cho cùng một chỉ số vị trí không có ảnh hưởng thực tế nhiều.</li>
</ol>
<p>Một phương pháp như vậy, được gọi là “grouped attention” vì chúng ta gom nhóm một số token vào cùng một nhúng vị trí, thực hiện một cách tương đương với các kỹ thuật tinh chỉnh cho việc mở rộng cửa sổ ngữ cảnh và chỉ đòi hỏi sửa đổi mã tối thiểu (tức là chỉ bốn dòng mã bổ sung trong PyTorch).</p>
<p>Self Extend. Nếu chúng ta áp dụng grouped attention một cách ngây thơ, hiệu suất mô hình ngôn ngữ sẽ hao mòn một cách nhẹ, vì token trong toàn bộ chuỗi sẽ được ánh xạ vào các nhóm chia sẻ cùng một chỉ số vị trí. Để giải quyết vấn đề này, chúng ta cần nhận ra rằng các token lân cận quan trọng nhất khi tạo ra một token với một LLM. Do đó, chúng ta có thể loại bỏ sự suy giảm hiệu suất này bằng:</p>
<ol>
<li>Định nghĩa một kích cỡ vùng lân cận của các token gần đây nhất mà trên đó ánh xạ attention thông thường được áp dụng.</li>
<li>Sử dụng grouped attention cho các token xa hơn trong chuỗi.</li>
</ol>
<p>Một cách mánh khóe cuối cùng này hình thành kỹ thuật Self Extend, mà có thể được sử dụng để tăng độ dài ngữ cảnh của bất kỳ LLM nào trong quá trình suy luận mà không cần tinh chỉnh." | Nitter
x.com/cwolferesearch/status/1748393116338409890#m</p>
</blockquote>
<p>Các khả năng học thông tin trong bối cảnh của LLM đã tạo ra nhu cầu cho cửa sổ ngữ cảnh lớn hơn. Gần đây, các nhà n</p>
        </div><br><br><br><br><br><br>
    </div>

</div>
<div class="flex flex-col fixed bottom-0 w-full subcard backdrop-filter backdrop-blur-lg">
    <div class="text-sm px-2 pb-2 pt-2">
        <form id="subscribe-form" action="/subscribe" method="post" class="flex flex-col mb-2">
            <div class="flex items-center  w-full">
                <input type="number" name="target_id" placeholder="Enter target ID" required
                       class="m-1 border border-gray-300 rounded px-4 py-1 focus:outline-none focus:ring focus:border-blue-300  w-full">
                <a href="https://business.twitter.com/en/blog/twitter-101-lists.html" target="_blank"
                   rel="noopener noreferrer"
                   class="border border-white rounded px-3 py-1  mr-2">
                    ?
                </a>
            </div>
            <div class="flex items-center mt-1 w-full">
                <input type="email" name="email" placeholder="Enter your email address" required
                       class="m-1 border border-gray-300 rounded px-4 py-1 focus:outline-none focus:ring focus:border-blue-300 w-full max-w-xs">
                <select id="language-select"
                        class="w-1/2 border border-white mr-1 ml-auto bg-transparent py-1 rounded">
                    <option value="zh-CN">简体中文</option>
                    <option value="zh-TW">繁體中文</option>
                    <option value="en">English</option>
                    <option value="ja">日本語</option>
                    <option value="ko">한국어</option>
                    <option value="es">Español</option>
                    <option value="pt">Português</option>
                    <option value="de">Deutsch</option>
                    <option value="fr">Français</option>
                    <option value="ar">العربية</option>
                    <option value="id">Bahasa Indonesia</option>
                    <option value="ms">Bahasa Melayu</option>
                    <option value="tl">Filipino</option>
                    <option value="vi">Tiếng Việt</option>
                    <option value="pl">Polski</option>
                    <option value="nl">Nederlands</option>
                    <option value="th">ไทย</option>
                </select>
            </div>
            <div class="flex mt-1 w-full">
                <input type="time" id="mail-time" required
                       class="w-20 m-1 border border-gray-300 rounded-full py-1 focus:ring focus:border-blue-300">
                <button type="submit" class="bg-blue-500 text-white py-1 rounded-full m-1 w-full"
                        id="subscribe-btn">Subscribe
                </button>
                <input type="hidden" name="mail_time" id="mail-time-timestamp" value="">
            </div>
            <input type="hidden" name="current_language" id="current-language" value="">

        </form>
        <span class="text-xs" id="time-label">Daily Push Time</span><span class="fixed bottom-2 right-2">© subxTwitter 2024</span>
    </div>
</div>
</body>
<script src="/static/index.js"></script>
</html>